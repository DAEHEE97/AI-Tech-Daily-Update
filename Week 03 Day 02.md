# Week 03 Day 02

- 2023년 11월 21일 (화)

---

## Insights

1) [DL Basic] Convolutional Neural Network
    - Convolution operation (합성곱 연산)
    - CNN Weight
    - CNN Bias
    - 3차원 텐서의 Convolution operation (합성곱 연산)
    - Stack of Convolutions
    - Convolution Arithmetic
    - Pooling layer (풀링 층)
    - Fully-Connteced layer (완전 연결 계층)
    - 1x1 Convolution
    
    > Newral Network 의 깊이는 깊게가져가면서, 파라미터 수를 줄여 성능 up!
    
    > layer 별로 몇개 의 parameters 들이 어떻게 이루어져있고, 전체 parameters 개수가 몇개인지 감을 가지고 있는것도 중요!


2) [DL Basic] Recurrent Neural Network
    - 순환 신경망(Recurrent Neural Network, RNN)
    - RNN 수식
    - Long Short-Term Memory, LSTM
    - Gated Recurrent Unit, GRU
    
    > RNN 직전 가중치를 다시 가져와서 처리, LSTM 게이트 3개추가 더 이전 가중치들까지 처리, 파라미터 증가, GRU 게이트 하나 줄여서 처리


---

## Peer session

- Daily-Code-Challenge
    - LV1-시저 암호
    - LV2-의상

---

## Wrap-up

- 순 공부 시간 체크

- 루틴 만들기
    - 1 day 1 update
    - 식사 후 산책
    - 도핑
    - 17:30 ~ 19:00 
    - 운동

- 멋쟁이 거북이, 깊숙한 공부, 성장, 감사, 과정, 1.5

---

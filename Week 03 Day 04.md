# Week 03 Day 04

- 2023년 11월 23일 (목)

---

## Insights


1) [DL Basic] Sequence-to-Sequence, seq2seq

    - seq2seq 모델
    
    - seq2seq 동작 과정
        - Test 단계
        - Teacher forcing (Train 단계)
        - Embedding layer
        - RNN 셀
        - Decoder
        
    - Seq2Seq를 이용한 기계 번역기
    
    - BLEU(Bilingual Evaluation Understudy)

2) [DL Basic] Attention Mechanism
    - seq2seq 모델의 한게:
    
    - Attention Mechanism
    
    - Dot-Product Attention
        - 어텐션 스코어(Attention Score):
        - 어텐션 가중치 (Attention Weights)
        - 어텐션 값(Attention Value):
        
    - Attention Mechanism을 이용한 번역기 구현
        - 인코더 클래스
        - 디코더 클래스
        - Seq2Seq 모델 (인코더와 디코더 연결)

3) [DL Basic] Transformer

    - Transformer
        - Self-Attention
        - Query, Key, Value vectors
        - Positional Encoding
        
    - Scaled Dot-Product Attention (SDPA)
        - 구현: ScaledDotProductAttention 클래스
        
    - Multi-Headed Attention (MHA)

4) [AI-Data-Visualization] Python과 Matplotlib

    - 왜 Matplotlib일까?
        - import Library
        
    - 기본 Plot
        - Figure와 Axes
        - plt로 그래프 그리기
        - 서브플롯 객체 ax에 그리기
        
    - Plot의 요소들 알아보기
        - 한 서브플롯에서 여러 개 그리기
        - 색상 지정하기
        - 텍스트 사용하기

---

## Peer session

- 마스터 클래스
    - 배워서 남주자 
    - 깃허브 말고 블로그 노션 생각해보기
    - 성장
   
   
- Daily-Code-Challenge

    - LV1-자연수 뒤집어 배열로 만들기
    - LV2-연속 부분 수열 합의 개수

---

## Wrap-up

- 과제 마무리 제대로 하자

- 루틴 만들기
    - 1 day 1 update
    - 식사 후 산책
    - 도핑
    - 17:30 ~ 19:00 
    - 운동

- 성장, 감사, 과정, 1.5

---
